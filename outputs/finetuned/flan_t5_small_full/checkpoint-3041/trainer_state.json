{
  "best_global_step": 3000,
  "best_metric": 0.1405,
  "best_model_checkpoint": "outputs\\finetuned\\flan_t5_small_full\\checkpoint-3000",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3041,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01644195988161789,
      "grad_norm": 2.1250197887420654,
      "learning_rate": 2.66304347826087e-05,
      "loss": 4.1264,
      "step": 50
    },
    {
      "epoch": 0.03288391976323578,
      "grad_norm": 1.5348457098007202,
      "learning_rate": 4.988131570023737e-05,
      "loss": 3.596,
      "step": 100
    },
    {
      "epoch": 0.04932587964485367,
      "grad_norm": 1.5284563302993774,
      "learning_rate": 4.9033570701932865e-05,
      "loss": 3.2529,
      "step": 150
    },
    {
      "epoch": 0.06576783952647156,
      "grad_norm": 1.6966384649276733,
      "learning_rate": 4.818582570362835e-05,
      "loss": 3.1158,
      "step": 200
    },
    {
      "epoch": 0.08220979940808945,
      "grad_norm": 1.5175330638885498,
      "learning_rate": 4.733808070532384e-05,
      "loss": 2.9877,
      "step": 250
    },
    {
      "epoch": 0.09865175928970733,
      "grad_norm": 1.4724615812301636,
      "learning_rate": 4.6490335707019336e-05,
      "loss": 2.9542,
      "step": 300
    },
    {
      "epoch": 0.11509371917132523,
      "grad_norm": 1.6441352367401123,
      "learning_rate": 4.564259070871482e-05,
      "loss": 2.9096,
      "step": 350
    },
    {
      "epoch": 0.1315356790529431,
      "grad_norm": 1.5575978755950928,
      "learning_rate": 4.479484571041031e-05,
      "loss": 2.8722,
      "step": 400
    },
    {
      "epoch": 0.147977638934561,
      "grad_norm": 2.172311544418335,
      "learning_rate": 4.39471007121058e-05,
      "loss": 2.8499,
      "step": 450
    },
    {
      "epoch": 0.1644195988161789,
      "grad_norm": 1.3141593933105469,
      "learning_rate": 4.309935571380129e-05,
      "loss": 2.8123,
      "step": 500
    },
    {
      "epoch": 0.1644195988161789,
      "eval_bleu": 0.0326,
      "eval_chrf": 5.2887,
      "eval_loss": 2.5039353370666504,
      "eval_runtime": 565.1364,
      "eval_samples_per_second": 5.381,
      "eval_steps_per_second": 2.691,
      "step": 500
    },
    {
      "epoch": 0.18086155869779677,
      "grad_norm": 1.8605433702468872,
      "learning_rate": 4.225161071549678e-05,
      "loss": 2.7597,
      "step": 550
    },
    {
      "epoch": 0.19730351857941467,
      "grad_norm": 1.616018533706665,
      "learning_rate": 4.140386571719227e-05,
      "loss": 2.7668,
      "step": 600
    },
    {
      "epoch": 0.21374547846103256,
      "grad_norm": 1.6557714939117432,
      "learning_rate": 4.0556120718887756e-05,
      "loss": 2.7294,
      "step": 650
    },
    {
      "epoch": 0.23018743834265046,
      "grad_norm": 1.720070481300354,
      "learning_rate": 3.970837572058325e-05,
      "loss": 2.7163,
      "step": 700
    },
    {
      "epoch": 0.24662939822426833,
      "grad_norm": 1.411358118057251,
      "learning_rate": 3.886063072227874e-05,
      "loss": 2.6882,
      "step": 750
    },
    {
      "epoch": 0.2630713581058862,
      "grad_norm": 1.3330602645874023,
      "learning_rate": 3.801288572397423e-05,
      "loss": 2.6559,
      "step": 800
    },
    {
      "epoch": 0.2795133179875041,
      "grad_norm": 1.423504114151001,
      "learning_rate": 3.7165140725669725e-05,
      "loss": 2.6449,
      "step": 850
    },
    {
      "epoch": 0.295955277869122,
      "grad_norm": 1.498803973197937,
      "learning_rate": 3.631739572736521e-05,
      "loss": 2.6515,
      "step": 900
    },
    {
      "epoch": 0.3123972377507399,
      "grad_norm": 1.7089779376983643,
      "learning_rate": 3.54696507290607e-05,
      "loss": 2.6279,
      "step": 950
    },
    {
      "epoch": 0.3288391976323578,
      "grad_norm": 1.3917880058288574,
      "learning_rate": 3.462190573075619e-05,
      "loss": 2.6085,
      "step": 1000
    },
    {
      "epoch": 0.3288391976323578,
      "eval_bleu": 0.0808,
      "eval_chrf": 6.4348,
      "eval_loss": 2.34603214263916,
      "eval_runtime": 571.9003,
      "eval_samples_per_second": 5.317,
      "eval_steps_per_second": 2.66,
      "step": 1000
    },
    {
      "epoch": 0.34528115751397565,
      "grad_norm": 1.5242605209350586,
      "learning_rate": 3.377416073245168e-05,
      "loss": 2.6043,
      "step": 1050
    },
    {
      "epoch": 0.36172311739559354,
      "grad_norm": 1.9965345859527588,
      "learning_rate": 3.292641573414717e-05,
      "loss": 2.5918,
      "step": 1100
    },
    {
      "epoch": 0.37816507727721144,
      "grad_norm": 1.7316372394561768,
      "learning_rate": 3.207867073584266e-05,
      "loss": 2.5721,
      "step": 1150
    },
    {
      "epoch": 0.39460703715882933,
      "grad_norm": 1.579290509223938,
      "learning_rate": 3.123092573753815e-05,
      "loss": 2.5792,
      "step": 1200
    },
    {
      "epoch": 0.41104899704044723,
      "grad_norm": 1.3094422817230225,
      "learning_rate": 3.0383180739233642e-05,
      "loss": 2.5839,
      "step": 1250
    },
    {
      "epoch": 0.4274909569220651,
      "grad_norm": 1.4821597337722778,
      "learning_rate": 2.953543574092913e-05,
      "loss": 2.5707,
      "step": 1300
    },
    {
      "epoch": 0.443932916803683,
      "grad_norm": 1.2961032390594482,
      "learning_rate": 2.868769074262462e-05,
      "loss": 2.5279,
      "step": 1350
    },
    {
      "epoch": 0.4603748766853009,
      "grad_norm": 1.4910486936569214,
      "learning_rate": 2.7839945744320113e-05,
      "loss": 2.5156,
      "step": 1400
    },
    {
      "epoch": 0.47681683656691876,
      "grad_norm": 1.5360658168792725,
      "learning_rate": 2.69922007460156e-05,
      "loss": 2.5487,
      "step": 1450
    },
    {
      "epoch": 0.49325879644853665,
      "grad_norm": 1.30892813205719,
      "learning_rate": 2.6144455747711087e-05,
      "loss": 2.5379,
      "step": 1500
    },
    {
      "epoch": 0.49325879644853665,
      "eval_bleu": 0.1108,
      "eval_chrf": 6.4474,
      "eval_loss": 2.260929584503174,
      "eval_runtime": 565.9895,
      "eval_samples_per_second": 5.373,
      "eval_steps_per_second": 2.687,
      "step": 1500
    },
    {
      "epoch": 0.5097007563301545,
      "grad_norm": 1.567763328552246,
      "learning_rate": 2.529671074940658e-05,
      "loss": 2.498,
      "step": 1550
    },
    {
      "epoch": 0.5261427162117724,
      "grad_norm": 1.3885796070098877,
      "learning_rate": 2.4448965751102072e-05,
      "loss": 2.5112,
      "step": 1600
    },
    {
      "epoch": 0.5425846760933903,
      "grad_norm": 1.6116259098052979,
      "learning_rate": 2.360122075279756e-05,
      "loss": 2.5158,
      "step": 1650
    },
    {
      "epoch": 0.5590266359750082,
      "grad_norm": 1.5595823526382446,
      "learning_rate": 2.275347575449305e-05,
      "loss": 2.5167,
      "step": 1700
    },
    {
      "epoch": 0.5754685958566261,
      "grad_norm": 1.4434912204742432,
      "learning_rate": 2.190573075618854e-05,
      "loss": 2.4912,
      "step": 1750
    },
    {
      "epoch": 0.591910555738244,
      "grad_norm": 1.2934235334396362,
      "learning_rate": 2.105798575788403e-05,
      "loss": 2.4844,
      "step": 1800
    },
    {
      "epoch": 0.6083525156198619,
      "grad_norm": 1.2600377798080444,
      "learning_rate": 2.0210240759579517e-05,
      "loss": 2.4706,
      "step": 1850
    },
    {
      "epoch": 0.6247944755014798,
      "grad_norm": 1.2199221849441528,
      "learning_rate": 1.936249576127501e-05,
      "loss": 2.4788,
      "step": 1900
    },
    {
      "epoch": 0.6412364353830977,
      "grad_norm": 1.4699182510375977,
      "learning_rate": 1.8514750762970498e-05,
      "loss": 2.4869,
      "step": 1950
    },
    {
      "epoch": 0.6576783952647156,
      "grad_norm": 1.545298457145691,
      "learning_rate": 1.766700576466599e-05,
      "loss": 2.4768,
      "step": 2000
    },
    {
      "epoch": 0.6576783952647156,
      "eval_bleu": 0.1194,
      "eval_chrf": 6.6456,
      "eval_loss": 2.2122106552124023,
      "eval_runtime": 523.0881,
      "eval_samples_per_second": 5.814,
      "eval_steps_per_second": 2.908,
      "step": 2000
    },
    {
      "epoch": 0.6741203551463334,
      "grad_norm": 1.382794737815857,
      "learning_rate": 1.681926076636148e-05,
      "loss": 2.4915,
      "step": 2050
    },
    {
      "epoch": 0.6905623150279513,
      "grad_norm": 1.8782938718795776,
      "learning_rate": 1.597151576805697e-05,
      "loss": 2.4603,
      "step": 2100
    },
    {
      "epoch": 0.7070042749095692,
      "grad_norm": 1.3977164030075073,
      "learning_rate": 1.512377076975246e-05,
      "loss": 2.4586,
      "step": 2150
    },
    {
      "epoch": 0.7234462347911871,
      "grad_norm": 1.422463297843933,
      "learning_rate": 1.4276025771447949e-05,
      "loss": 2.469,
      "step": 2200
    },
    {
      "epoch": 0.739888194672805,
      "grad_norm": 1.385030746459961,
      "learning_rate": 1.342828077314344e-05,
      "loss": 2.4744,
      "step": 2250
    },
    {
      "epoch": 0.7563301545544229,
      "grad_norm": 1.6039409637451172,
      "learning_rate": 1.2580535774838928e-05,
      "loss": 2.4643,
      "step": 2300
    },
    {
      "epoch": 0.7727721144360408,
      "grad_norm": 1.6398483514785767,
      "learning_rate": 1.1732790776534419e-05,
      "loss": 2.4559,
      "step": 2350
    },
    {
      "epoch": 0.7892140743176587,
      "grad_norm": 1.6797062158584595,
      "learning_rate": 1.0885045778229909e-05,
      "loss": 2.4639,
      "step": 2400
    },
    {
      "epoch": 0.8056560341992766,
      "grad_norm": 1.342459797859192,
      "learning_rate": 1.00373007799254e-05,
      "loss": 2.4394,
      "step": 2450
    },
    {
      "epoch": 0.8220979940808945,
      "grad_norm": 1.243460774421692,
      "learning_rate": 9.189555781620888e-06,
      "loss": 2.4575,
      "step": 2500
    },
    {
      "epoch": 0.8220979940808945,
      "eval_bleu": 0.1304,
      "eval_chrf": 6.7999,
      "eval_loss": 2.1851792335510254,
      "eval_runtime": 567.6535,
      "eval_samples_per_second": 5.357,
      "eval_steps_per_second": 2.679,
      "step": 2500
    },
    {
      "epoch": 0.8385399539625124,
      "grad_norm": 1.491971492767334,
      "learning_rate": 8.341810783316379e-06,
      "loss": 2.4194,
      "step": 2550
    },
    {
      "epoch": 0.8549819138441302,
      "grad_norm": 1.7328366041183472,
      "learning_rate": 7.4940657850118685e-06,
      "loss": 2.4364,
      "step": 2600
    },
    {
      "epoch": 0.8714238737257481,
      "grad_norm": 1.3612178564071655,
      "learning_rate": 6.646320786707359e-06,
      "loss": 2.4261,
      "step": 2650
    },
    {
      "epoch": 0.887865833607366,
      "grad_norm": 1.2945014238357544,
      "learning_rate": 5.7985757884028486e-06,
      "loss": 2.4078,
      "step": 2700
    },
    {
      "epoch": 0.9043077934889839,
      "grad_norm": 1.4537341594696045,
      "learning_rate": 4.950830790098339e-06,
      "loss": 2.4277,
      "step": 2750
    },
    {
      "epoch": 0.9207497533706018,
      "grad_norm": 1.2355401515960693,
      "learning_rate": 4.103085791793829e-06,
      "loss": 2.4496,
      "step": 2800
    },
    {
      "epoch": 0.9371917132522196,
      "grad_norm": 1.4200628995895386,
      "learning_rate": 3.2553407934893183e-06,
      "loss": 2.4325,
      "step": 2850
    },
    {
      "epoch": 0.9536336731338375,
      "grad_norm": 1.5064424276351929,
      "learning_rate": 2.4075957951848088e-06,
      "loss": 2.43,
      "step": 2900
    },
    {
      "epoch": 0.9700756330154554,
      "grad_norm": 1.5281181335449219,
      "learning_rate": 1.5598507968802984e-06,
      "loss": 2.4247,
      "step": 2950
    },
    {
      "epoch": 0.9865175928970733,
      "grad_norm": 1.5873498916625977,
      "learning_rate": 7.121057985757884e-07,
      "loss": 2.4375,
      "step": 3000
    },
    {
      "epoch": 0.9865175928970733,
      "eval_bleu": 0.1405,
      "eval_chrf": 6.8534,
      "eval_loss": 2.1762568950653076,
      "eval_runtime": 538.1167,
      "eval_samples_per_second": 5.651,
      "eval_steps_per_second": 2.827,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3041,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 804144169979904.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
